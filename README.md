# ğŸš– NYC Taxi End-to-End Data Engineering Project  

An interactive **end-to-end data engineering pipeline** built on **Azure**, using the **NYC Taxi dataset** as a real-world case study. This project demonstrates how to design scalable pipelines, handle real-time ingestion, transform raw data into analytics-ready formats, and serve insights with modern cloud tools.  

---  

## âœ¨ Project Overview  

- **Data Source**: NYC Taxi public dataset (Parquet format + Lookup CSVs)  
- **Architecture**: Follows the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold)  
- **Pipeline Type**: **Dynamic & Parameterized** pipelines using **Azure Data Factory (ADF)**  
- **Processing Engine**: **Databricks + PySpark** for transformations  
- **Storage**: **Azure Data Lake Storage Gen2 (ADLS)** with Delta Lake  
- **Serving Layer**: Data made available for **Power BI / analytics tools**  
- **Security**: Managed Identities + Role-based Access  

---  

## ğŸ—ï¸ Architecture  

```mermaid
flowchart LR
    API[NYC Taxi API] --> ADF[Azure Data Factory: Dynamic Pipelines] --> Bronze[Bronze Layer (Raw Data)]
    Bronze -->|PySpark in Databricks| Silver[Silver Layer (Cleaned & Processed)]
    Silver -->|Delta Lake (ACID, Time Travel)| Gold[Gold Layer (Analytics-Ready)]
    Gold --> PowerBI[Power BI / Analytics Tools]
```  

- **Bronze Layer**: Raw parquet files fetched dynamically from APIs  
- **Silver Layer**: Cleaned, structured data with applied business rules  
- **Gold Layer**: Curated, optimized Delta tables for BI and ML use cases  

---  

## ğŸ”‘ Key Features  

- ğŸ“¡ **Dynamic API Ingestion**: Automated monthly pulls (no manual uploads!)  
- ğŸ”„ **Parameterized Pipelines**: Reusable ADF datasets, linked services, loops  
- ğŸ—‚ï¸ **Delta Lake**: Versioning, time-travel, ACID transactions, schema evolution  
- âš¡ **PySpark Optimizations**: Partitioning, transformations, and data quality checks  
- ğŸ” **Security Best Practices**: Managed identities for access control  
- ğŸ“Š **Analytics Ready**: Gold data directly consumed by Power BI dashboards  

---  

## ğŸ› ï¸ Tech Stack  

- **Cloud**: Azure (Data Factory, Databricks, ADLS Gen2)  
- **Processing**: PySpark, Delta Lake  
- **Storage Format**: Parquet + Delta  
- **Visualization**: Power BI  
- **Version Control & CI/CD**: GitHub + Git  

---  

## ğŸš€ Workflow  

1. **Ingestion**  
   - ADF dynamically calls NYC Taxi APIs  
   - Monthly data pulled into **Bronze Layer** (Parquet format)  

2. **Processing**  
   - Databricks (PySpark) cleans & transforms  
   - Writes results into **Silver Layer**  

3. **Enrichment**  
   - Lookup data (Taxi Zones) joined at Silver stage  
   - Schema evolution + partitioning applied  

4. **Curated Gold Data**  
   - Delta tables with **time travel & ACID guarantees**  
   - Ready for **reporting, ML, and analytics**  

5. **Consumption**  
   - Power BI connects directly to Gold layer  
   - Interactive dashboards for insights  

---  

## ğŸ“‚ Project Structure  

```
NYC-Taxi-DataEngineering-Project/
â”‚â”€â”€ data/                # Sample lookup CSVs  
â”‚â”€â”€ notebooks/           # PySpark transformation notebooks  
â”‚â”€â”€ pipelines/           # ADF JSON pipeline definitions  
â”‚â”€â”€ docs/                # Architecture diagrams & notes  
â”‚â”€â”€ README.md            # Project documentation  
```  

---  

## ğŸ“ˆ Outcomes  

- âœ… Automated ingestion from APIs (no manual effort)  
- âœ… Optimized transformations using PySpark & Databricks  
- âœ… Reliable storage with Delta Lake (ACID, time travel, schema evolution)  
- âœ… Analytics-ready data served directly to Power BI  

---  

## ğŸ¯ Why This Project Matters  

This project is a **complete data engineering pipeline** that reflects **real-world practices** used in the industry. It covers:  
- Data ingestion at scale  
- Transformation using Spark-based frameworks  
- Data governance with Delta Lake  
- BI-ready serving layer for analytics  

Itâ€™s not just a demo â€” itâ€™s an **end-to-end implementation** showing how raw data turns into business-ready insights.  

---  

## ğŸ“Œ Next Steps  

- Add real-time streaming ingestion with **Azure Event Hubs**  
- Extend governance with **Unity Catalog**  
- Deploy CI/CD pipelines for production readiness  

---  

## ğŸ§‘â€ğŸ’» Author  

**Tushar Kaushik**  
ğŸ“ MS in Applied Data Science â€” University of Southern California (USC)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/tushar-kaushik-493a8115a/) | ğŸ“§ kaushiktk015@gmail.com  

---  
